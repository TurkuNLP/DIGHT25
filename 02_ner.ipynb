{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPYrNyJq/92OH1EPpKEyH5t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/DIGHT25/blob/main/02_ner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSPy tutorial part 2\n",
        "\n",
        "* Grabs a dataset of tweets and looks for entities and their types\n"
      ],
      "metadata": {
        "id": "iay3NUGGT8IM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q dspy\n",
        "!wget https://github.com/TurkuNLP/DIGHT25/raw/refs/heads/main/wnut17_300.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "r1HJ7-_2VIrY",
        "outputId": "da8eedbc-7a64-4ee0-d554-bd523e840b44"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.1/260.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h--2025-08-27 15:53:40--  https://github.com/TurkuNLP/DIGHT25/raw/refs/heads/main/wnut17_300.csv\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/TurkuNLP/DIGHT25/refs/heads/main/wnut17_300.csv [following]\n",
            "--2025-08-27 15:53:40--  https://raw.githubusercontent.com/TurkuNLP/DIGHT25/refs/heads/main/wnut17_300.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 34227 (33K) [text/plain]\n",
            "Saving to: ‘wnut17_300.csv’\n",
            "\n",
            "wnut17_300.csv      100%[===================>]  33.42K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-08-27 15:53:40 (2.09 MB/s) - ‘wnut17_300.csv’ saved [34227/34227]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "gXPQHftbOYT8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ps7bw_9GtJKP"
      },
      "outputs": [],
      "source": [
        "import csv, dspy, json, random\n",
        "\n",
        "class SimpleEnglishNER(dspy.Signature):\n",
        "    \"\"\"Extract entities as a list:\n",
        "    [{\"text\":\"Barack Obama\",\"type\":\"PERSON\"}, {\"text\":\"Berlin\",\"type\":\"LOCATION\"}]\n",
        "    Allowed types: PERSON, LOCATION, GROUP, CORPORATION, CREATIVE_WORK, PRODUCT.\n",
        "\n",
        "    Hashtag and @ should be included as part of the text.\n",
        "    \"\"\"\n",
        "    text = dspy.InputField(desc=\"a tweet\")\n",
        "    entities = dspy.OutputField(desc=\"a list\")\n",
        "\n",
        "# configure your model (edit to your backend/key)\n",
        "lm=dspy.LM(\"openai/gpt-4.1-mini\",api_key=userdata.get('openai-api-key'))\n",
        "dspy.configure(lm=lm)\n",
        "\n",
        "predict = dspy.Predict(signature=SimpleEnglishNER)\n",
        "\n",
        "with open(\"wnut17_300.csv\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    r = csv.DictReader(f,fieldnames=[\"entities\", \"text\"])\n",
        "    rows = [row for row in r]\n",
        "random.shuffle(rows)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for row in rows[:10]: #only take first 10 rows\n",
        "    text = row[\"text\"]\n",
        "    out = predict(text=text)\n",
        "    pred = out.entities\n",
        "    print(\"TEXT:\", text)\n",
        "    print(\"PRED:\", pred)\n",
        "    print()"
      ],
      "metadata": {
        "id": "uZT4czB3PjfF",
        "outputId": "92215381-c72a-4d30-bcc6-5009b6712c08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXT: sfitzy93 asked : No problem ( : awesome ! toast = life :P .. You doing anything for the day ? http://tumblr.com/xkdiufb81\n",
            "PRED: []\n",
            "\n",
            "TEXT: I feel like there was something i as suppossed to do today ....\n",
            "PRED: []\n",
            "\n",
            "TEXT: I'm feelin better than some head on a Sunday afternoon , better than a chick that said yes too soon .\n",
            "PRED: []\n",
            "\n",
            "TEXT: @hannibal_flow I got miami pics for days lol\n",
            "PRED: [{\"text\":\"@hannibal_flow\",\"type\":\"PERSON\"}, {\"text\":\"miami\",\"type\":\"LOCATION\"}]\n",
            "\n",
            "TEXT: @lexi_nicole2010 That 's not the story by a long shot biotch !\n",
            "PRED: [{\"text\":\"@lexi_nicole2010\",\"type\":\"PERSON\"}]\n",
            "\n",
            "TEXT: @daraobriain hmmm . Cant wait . Comin on Thursday . First time to the Apollo .\n",
            "PRED: [{\"text\":\"@daraobriain\",\"type\":\"PERSON\"}, {\"text\":\"Apollo\",\"type\":\"LOCATION\"}]\n",
            "\n",
            "TEXT: 'RT @amandacarolinne : \" Danger Days : The True Lives Of The Fabulous Killjoys \"'\n",
            "PRED: [{\"text\":\"@amandacarolinne\",\"type\":\"PERSON\"}, {\"text\":\"Danger Days : The True Lives Of The Fabulous Killjoys\",\"type\":\"CREATIVE_WORK\"}]\n",
            "\n",
            "TEXT: Always kinda awkward when you get the chat group wrong in WoW . Sometimes you don't want the tank to know you're dissin ' him . Oops .\n",
            "PRED: [{\"text\":\"WoW\",\"type\":\"PRODUCT\"}]\n",
            "\n",
            "TEXT: @Jfordj12 Wee need u to make it happen on Sunday\n",
            "PRED: [{\"text\":\"@Jfordj12\",\"type\":\"PERSON\"}]\n",
            "\n",
            "TEXT: RT @m_candelaria : The amazing Follow Friday Train : @Sketchjobs @lollieshopping @philadelphiabn @elainebiss @TableMatters10 @STALKmyPRETT ...\n",
            "PRED: [{\"text\":\"@m_candelaria\",\"type\":\"PERSON\"}, {\"text\":\"@Sketchjobs\",\"type\":\"PERSON\"}, {\"text\":\"@lollieshopping\",\"type\":\"PERSON\"}, {\"text\":\"@philadelphiabn\",\"type\":\"PERSON\"}, {\"text\":\"@elainebiss\",\"type\":\"PERSON\"}, {\"text\":\"@TableMatters10\",\"type\":\"PERSON\"}, {\"text\":\"@STALKmyPRETT\",\"type\":\"PERSON\"}]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tasks:\n",
        "\n",
        "1. Are you happy with the result?\n",
        "2. Can you make the model guess e.g. types of products? Does the result align with your intuition?\n"
      ],
      "metadata": {
        "id": "-BLuODsDUsCW"
      }
    }
  ]
}